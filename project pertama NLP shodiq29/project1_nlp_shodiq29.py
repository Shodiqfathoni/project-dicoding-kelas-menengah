# -*- coding: utf-8 -*-
"""project NLP shodiq29

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U5aCtHjB_ROWwNkD5dJzFzRbtxHp3jvI

# DATA DIRI
- Nama: Muhammad Shodiq Fathoni
- Email: shodiqfathoni3@gmail.com
- Id Dicoding: shodiq29

# project Membuat Model NLP dengan TensorFlow

### langkah 1 : memasukkan data set rental mobil dan menghapus kolom yang tidak diperlukan
"""

import pandas as pd
df = pd.read_csv('/content/CarRentalData.csv')
df = df.drop(columns=['fuelType', 'rating', 'renterTripsTaken', 'reviewCount',
                      'location.country', 'location.latitude',
                      'location.longitude', 'location.state', 'owner.id', 'rate.daily',
                      'location.city', 'vehicle.model', 'vehicle.year'])
df.tail()

"""### langkah 2 : mengganti nama kolom agar tidak terjadi error saat coding"""

df = df.rename(columns={'vehicle.make': 'brand', 'vehicle.type': 'type_car'})
df.tail()

"""### langkah 3 : mendefinisikan ulang kategori tipe mobil"""

def tipe_categories(category):
    if category=='car' or category=='suv':
        return 'suv'
    elif category=='van':
        return 'van'
    elif category=='minivan':
        return 'minivan'
    else:
        return 'truck'

df['type_car']=df['type_car'].apply(tipe_categories)

"""### langkah 4 : mendetailkan kondisi jika terpenuhi adalah 1 dan tidak 0"""

category = pd.get_dummies(df.type_car)
df_baru = pd.concat([df, category], axis=1)
df_baru = df_baru.drop(columns='type_car')
df_baru

"""### langkah 5 : mendefinisikan deskripsi dan label yang akan di klasifikasi"""

brand = df_baru['brand'].values
label = df_baru[['minivan','suv','truck','van']].values

"""### langkah 6 : membagi validation set sebesar 20% dari total data"""

from sklearn.model_selection import train_test_split
brand_latih, brand_test, label_latih, label_test = train_test_split(brand, label, test_size=0.2)

"""### langkah 7 : gunakan tokenizer untuk memproses larik deskripsi diatas menjadi token numerik"""

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer(num_words=5000, oov_token='x')
tokenizer.fit_on_texts(brand_latih)


sekuens_latih = tokenizer.texts_to_sequences(brand_latih)
sekuens_test = tokenizer.texts_to_sequences(brand_test)

padded_latih = pad_sequences(sekuens_latih)
padded_test = pad_sequences(sekuens_test)

"""### langkah 8 : membuat layer embedding,LSTM dan ditambah dropout"""

import tensorflow as tf
model = tf.keras.Sequential([
        tf.keras.layers.Embedding(input_dim=5000, output_dim=16),
        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, recurrent_dropout=0.2,return_sequences=True)),
        tf.keras.layers.LSTM(64),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(32, activation='relu'),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.Dense(4, activation='softmax')
])
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

"""### langkah 9 : membuat callback dengan akurasi > 90%"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.92):
      print("\nAkurasi telah mencapai >90%!")
      self.model.stop_training = True
callbacks = myCallback()

"""### langkah 10 : membuat model fit dengan jumlah epochs 30"""

num_epochs = 30
history = model.fit(padded_latih, label_latih, epochs=num_epochs,
                    validation_data=(padded_test, label_test),
                    batch_size=128,
                    steps_per_epoch=25,
                    validation_steps=5,
                    verbose=2,callbacks=[callbacks])

"""### langkah 11 : membuat plot accuracy dan loss"""

import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('accuracy')
plt.xlabel('Epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.show()