# -*- coding: utf-8 -*-
"""final project 3 model gambar

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LLPhaAJtd4-NYMcvbI5jUyG5KLI34te2

# DATA DIRI
- Nama: Muhammad Shodiq Fathoni
- Email: shodiqfathoni3@gmail.com
- Id Dicoding: shodiq29
"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os
import pandas as pd
from PIL import Image
import tensorflow as tf
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import pathlib

!mkdir /content/drive/MyDrive/setgw
!cp kaggle.json /content/drive/MyDrive/datasetgw/

!mkdir -p ~/.kaggle
!cp /content/drive/MyDrive/datasetgw/kaggle.json ~/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json

!kaggle datasets download -d hasibalmuzdadid/shoe-vs-sandal-vs-boot-dataset-15k-images

!unzip \*.zip && rm *.zip.

os.listdir('/content/Shoe vs Sandal vs Boot Dataset')

"""## **membagi data set 80% train & 20% validation**"""

train_dir = os.path.join('/content/Shoe vs Sandal vs Boot Dataset')
train_datagen = ImageDataGenerator(rescale=1./255,
    rotation_range=20,
    zoom_range=0.2,
    shear_range=0.2,
    fill_mode = 'nearest',
    validation_split=0.2)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=8,
    class_mode='categorical',
    subset='training')

validation_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=16,
    class_mode='categorical',
    subset='validation')

"""# **menampilkan sample ukuran resolusi gambar**"""

df = pd.DataFrame({'path': ['/content/Shoe vs Sandal vs Boot Dataset/Boot/boot (1).jpg',
                            '/content/Shoe vs Sandal vs Boot Dataset/Sandal/Sandal (1001).jpg',
                            '/content/Shoe vs Sandal vs Boot Dataset/Shoe/Shoe (1010).jpg']})


for path in df['path']:
    image_name = Image.open(path)
    print(image_name.size)

"""# **membuat model maxpooling layer**"""

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.4),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.4),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])

"""# **menerapkan callback akurasi 92%**"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.92 and logs.get('val_accuracy')>0.92):
      print("\nAkurasi train dan validasi didapat telah mencapai nilai > 92!")
      self.model.stop_training = True
callbacks = myCallback()

model.compile(optimizer=tf.optimizers.Adam(),
              loss='categorical_crossentropy',
              metrics = ['accuracy'])

num_epochs = 30
history = model.fit(train_generator,epochs=num_epochs,
                    validation_data=validation_generator,
                     batch_size=128,
                    steps_per_epoch=100,
                    validation_steps=5,
                    verbose=2,callbacks=[callbacks])

"""## **membuat plot loss dan akurasi**"""

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))

# Loss
ax1.plot(history.history['loss'])
ax1.plot(history.history['val_loss'])
ax1.legend(['Loss','Val Loss'])
ax1.set_xlabel('Epoch', fontsize=12)
ax1.set_ylabel('Loss', fontsize=12)
ax1.set_title('Loss', fontsize=20)

# MAE
ax2.plot(history.history['accuracy'])
ax2.plot(history.history['val_accuracy'])
ax2.legend(['accuracy','Val accuracy'])
ax2.set_xlabel('Epoch', fontsize=12)
ax2.set_ylabel('accuracy', fontsize=12)
ax2.set_title('accuracy', fontsize=20)
plt.show()

"""## **Menulis kode untuk menyimpan model ke dalam format TF-Lite.**"""

# Menyimpan model dalam format SavedModel
export_dir = 'saved_model/'
tf.saved_model.save(model, export_dir)

# Convert SavedModel menjadi shoe.tflite
converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()

tflite_model_file = pathlib.Path('shoe.tflite')
tflite_model_file.write_bytes(tflite_model)